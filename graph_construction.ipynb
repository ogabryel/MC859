{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003f7e6b",
   "metadata": {},
   "source": [
    "# Construção do grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b820095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import random\n",
    "import re\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc15780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_jobs = pd.read_csv(\"merged_data.csv\")\n",
    "technical_skills = pd.read_csv(\"technical_skills_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccdd44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associando um novo UUID para cada job\n",
    "scraped_jobs[\"id\"] = scraped_jobs[\"id\"].astype(\"str\")\n",
    "for i in range(scraped_jobs.shape[0]):\n",
    "    scraped_jobs.at[i, \"id\"] = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54277100",
   "metadata": {},
   "source": [
    "## Pré-processamento das localizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60578410",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_to_region = {\n",
    "    # Mapeamento dos estados para suas respectivas regiões\n",
    "    \"Acre\": \"North\",\n",
    "    \"Alagoas\": \"Northeast\",\n",
    "    \"Amapá\": \"North\",\n",
    "    \"Amazonas\": \"North\",\n",
    "    \"Bahia\": \"Northeast\",\n",
    "    \"Ceará\": \"Northeast\",\n",
    "    \"Distrito Federal\": \"Central-West\",\n",
    "    \"Espírito Santo\": \"Southeast\",\n",
    "    \"Goiás\": \"Central-West\",\n",
    "    \"Maranhão\": \"Northeast\",\n",
    "    \"Mato Grosso\": \"Central-West\",\n",
    "    \"Mato Grosso do Sul\": \"Central-West\",\n",
    "    \"Minas Gerais\": \"Southeast\",\n",
    "    \"Pará\": \"North\",\n",
    "    \"Paraíba\": \"Northeast\",\n",
    "    \"Paraná\": \"South\",\n",
    "    \"Pernambuco\": \"Northeast\",\n",
    "    \"Piauí\": \"Northeast\",\n",
    "    \"Rio de Janeiro\": \"Southeast\",\n",
    "    \"Rio Grande do Norte\": \"Northeast\",\n",
    "    \"Rio Grande do Sul\": \"South\",\n",
    "    \"Rondônia\": \"North\",\n",
    "    \"Roraima\": \"North\",\n",
    "    \"Santa Catarina\": \"South\",\n",
    "    \"São Paulo\": \"Southeast\",\n",
    "    \"Sergipe\": \"Northeast\",\n",
    "    \"Tocantins\": \"North\",\n",
    "    # Outras localidades disponíveis nas vagas\n",
    "    \"Federal District\": \"Central-West\",\n",
    "    \"Belo Horizonte\": \"Southeast\",\n",
    "    \"Porto Alegre\": \"South\",\n",
    "    \"Curitiba\": \"South\",\n",
    "    \"Campinas\": \"Southeast\",\n",
    "    \"Ribeirão Preto\": \"Southeast\",\n",
    "    \"Natal\": \"Northeast\",\n",
    "    \"Recife\": \"Northeast\",\n",
    "    \"Vitoria\": \"Southeast\",\n",
    "    \"Londrina\": \"South\",\n",
    "    \"Goiania\": \"Central-West\",\n",
    "    \"Brasilia\": \"Central-West\",\n",
    "    \"Salvador\": \"Northeast\",\n",
    "    \"Florianopolis\": \"South\",\n",
    "    \"Fortaleza\": \"Northeast\",\n",
    "    \"Belem\": \"North\",\n",
    "    \"Manaus\": \"North\",\n",
    "    \"João Pessoa\": \"Northeast\",\n",
    "    \"Cuiaba\": \"Central-West\",\n",
    "}\n",
    "\n",
    "\n",
    "# Remapeando localidades para a região a que pertencem\n",
    "def map_location(location):\n",
    "    \"\"\"\n",
    "    Remaps a location to its corresponding region in Brazil.\n",
    "    Args:\n",
    "        location (str): The location string to be remapped.\n",
    "    Returns:\n",
    "        str: The region corresponding to the location, or the original location if not found.\n",
    "    \"\"\"\n",
    "    for state, region in location_to_region.items():\n",
    "        if state in location:\n",
    "            return region\n",
    "    return location\n",
    "\n",
    "\n",
    "scraped_jobs[\"location\"] = scraped_jobs[\"location\"].apply(map_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7cb993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regiões para vagas não remotas: ['Southeast' 'South' 'Northeast' 'Central-West' 'North']\n",
      "Regiões para vagas remotas: ['Brazil' 'Southeast' 'South' 'Northeast' 'Central-West' 'North'\n",
      " 'Latin America']\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo as localizações das vagas não remotas\n",
    "print(\n",
    "    f\"Regiões para vagas não remotas: {scraped_jobs[scraped_jobs['remote'] == False]['location'].unique()}\"\n",
    ")\n",
    "\n",
    "# Imprimindo as localizações das vagas remotas\n",
    "print(\n",
    "    f\"Regiões para vagas remotas: {scraped_jobs[scraped_jobs['remote'] == True]['location'].unique()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a5551",
   "metadata": {},
   "source": [
    "Todas as vagas não remotas tiveram sua localização identificada. Para vagas remotas, faz sentido manter \"Brasil\" se não houver sido especificado a localização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57625d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mudando \"Latin America\" para \"Brazil\" para manter a consistência\n",
    "scraped_jobs[\"location\"] = scraped_jobs[\"location\"].replace(\"Latin America\", \"Brazil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae316170",
   "metadata": {},
   "source": [
    "## Identificação das habilidades técnicas a partir do título e da descrição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a39eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_splitter(skill):\n",
    "    \"\"\"\n",
    "    Returns a regex pattern to split text into tokens, ensuring characters existing in the given skill are preserved.\n",
    "    Args:\n",
    "        skill (str): The skill string to determine which characters to preserve.\n",
    "    Returns:\n",
    "        str: The regex pattern for token splitting.\n",
    "    \"\"\"\n",
    "    # Encontrando todos os caracteres que não são letras no conhecimento técnico\n",
    "    non_letters = set(re.findall(r\"[^a-zA-Z]\", skill))\n",
    "    escaped_non_letters = \"\".join([re.escape(c) for c in non_letters])\n",
    "\n",
    "    # Criando um padrão regex que corresponde a sequências de caracteres que não são letras, dígitos,\n",
    "    #    $, #, +, ou qualquer um dos caracteres não-letras presentes na skill\n",
    "    # Isso garante que caracteres como '+' em 'C++' sejam preservados como parte do token, e\n",
    "    #    evita dividir 'C++' em 'C' e '' o que poderia levar a falsos positivos\n",
    "    token_splitter = re.compile(rf\"[^\\w\\$\\#\\+{escaped_non_letters}]+\")\n",
    "    return token_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d29e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(string):\n",
    "    \"\"\"\n",
    "    Removes all numeric characters from the input string.\n",
    "    Args:\n",
    "        string (str): The input string from which numbers should be removed.\n",
    "    Returns:\n",
    "        str: The input string with all numeric characters removed.\n",
    "    \"\"\"\n",
    "    return re.sub(r\"\\d+\", \"\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db916e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills(job_title, job_description):\n",
    "    \"\"\"\n",
    "    Extracts technical skills from job title and description. The skills are matched using exact matching for skills with less than 6 characters, and fuzzy matching (normalized Indel similarity) for skills with 6 or more characters.\n",
    "    Args:\n",
    "        job_title (str): The job title.\n",
    "        job_description (str): The job description.\n",
    "    Returns:\n",
    "        list: A list of extracted technical skills.\n",
    "    \"\"\"\n",
    "    found_technical_skills = set()\n",
    "\n",
    "    # Removendo números (números de telefone, anos de experiência, versões de frameworks, etc.) do título e da descrição\n",
    "    job_title = remove_numbers(job_title)\n",
    "    job_description = remove_numbers(job_description)\n",
    "\n",
    "    title = job_title.lower()\n",
    "    description = job_description.lower()\n",
    "\n",
    "    for skill in technical_skills[\"skill\"]:\n",
    "        skill = skill.lower()\n",
    "        # Se a skill contém menos de 6 caracteres, usar a correspondência exata\n",
    "        if len(skill) < 6:\n",
    "            # Separando os tokens do título e da descrição\n",
    "            token_splitter = get_token_splitter(skill)\n",
    "            split_title = re.split(token_splitter, title)\n",
    "            split_description = re.split(token_splitter, description)\n",
    "\n",
    "            if skill in split_description or skill in split_title:\n",
    "                found_technical_skills.add(skill)\n",
    "        else:\n",
    "            # Usando fuzzy matching (normalized Indel similarity) para skills com 6 ou mais letras\n",
    "            minimum_match_score = int(\n",
    "                100 * len(skill) / (len(skill) + 1)\n",
    "            )  # no máximo 1 inserção/remoção\n",
    "\n",
    "            # Não considerar correspondências se a skill for maior que o texto sendo pesquisado\n",
    "            if (\n",
    "                len(skill) <= len(description)\n",
    "                and rapidfuzz.fuzz.partial_ratio(skill, description)\n",
    "                > minimum_match_score\n",
    "            ):\n",
    "                found_technical_skills.add(skill)\n",
    "            elif (\n",
    "                len(skill) <= len(title)\n",
    "                and rapidfuzz.fuzz.partial_ratio(skill, title) > minimum_match_score\n",
    "            ):\n",
    "                found_technical_skills.add(skill)\n",
    "\n",
    "    return list(found_technical_skills) if found_technical_skills else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0e5bf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas as vagas processadas, total feito 100%                                   \n"
     ]
    }
   ],
   "source": [
    "map_skills = True\n",
    "\n",
    "if map_skills:\n",
    "    # Criando uma nova coluna 'found_skills' para armazenar as skills extraídas antes da construção do grafo\n",
    "    scraped_jobs[\"found_skills\"] = np.empty((scraped_jobs.shape[0], 0)).tolist()\n",
    "\n",
    "    try:\n",
    "        for i in range(scraped_jobs.shape[0]):\n",
    "            # Adicionando à coluna 'found_skills' as skills extraídas do título e da descrição da vaga\n",
    "            scraped_jobs.at[i, \"found_skills\"] = extract_skills(\n",
    "                scraped_jobs[\"name\"].iloc[i], scraped_jobs[\"description\"].iloc[i]\n",
    "            )\n",
    "\n",
    "            if (i % 100) == 0:\n",
    "                print(\n",
    "                    f\"\\rProcessadas vagas até {i}, total feito {i / scraped_jobs.shape[0]}\".ljust(\n",
    "                        80\n",
    "                    ),\n",
    "                    end=\"\",\n",
    "                )\n",
    "\n",
    "        print(f\"\\rTodas as vagas processadas, total feito 100%\".ljust(80))\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProcesso interrompido.\".ljust(80))\n",
    "\n",
    "    # Salvando o dataframe com a nova coluna em um novo arquivo CSV\n",
    "    scraped_jobs.to_csv(\"scraped_jobs_with_skills.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cefb6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando 50 amostras aleatórias do dataframe em um novo arquivo CSV para verificação manual\n",
    "scraped_jobs.sample(n=50, random_state=random.seed(datetime.now().timestamp())).to_csv(\n",
    "    \"scraped_jobs_with_skills_sample.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0651a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo de scraped_jobs as linhas onde found_skills está vazio\n",
    "# Mesmo que palavras-chave relacionadas tenham sido usadas no processo de scraping,\n",
    "#    algumas vagas retornadas pela API são completamente não relacionadas à tecnologia\n",
    "scraped_jobs = scraped_jobs[scraped_jobs[\"found_skills\"].map(len) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a72474",
   "metadata": {},
   "source": [
    "## Construção do Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28dfe2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_from_csv = False\n",
    "\n",
    "if read_from_csv:\n",
    "    scraped_jobs = pd.read_csv(\"scraped_jobs_with_skills.csv\")\n",
    "    scraped_jobs[\"found_skills\"] = scraped_jobs[\"found_skills\"].apply(ast.literal_eval)\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# Criando arestas entre as vagas e skills\n",
    "for _, row in scraped_jobs.iterrows():\n",
    "    # Criando um novo nó para esta vaga\n",
    "    G.add_node(row[\"id\"], type=\"job\", location=row[\"location\"], remote=row[\"remote\"])\n",
    "    for skill in row[\"found_skills\"]:\n",
    "        # Criando um novo nó para a skill se ela não existir\n",
    "        if not G.has_node(skill):\n",
    "            G.add_node(skill, type=\"skill\")\n",
    "        # Criando uma aresta entre a vaga e a skill\n",
    "        G.add_edge(row[\"id\"], skill)\n",
    "\n",
    "# Salvando como GEXF\n",
    "nx.write_gexf(G, \"job_skill_graph.gexf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
