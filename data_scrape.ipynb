{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bedd89",
   "metadata": {},
   "source": [
    "# Coleta de vagas do Linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2d1789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cdadda",
   "metadata": {},
   "source": [
    "**Funções auxiliares:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d18897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page(url, verbose=False):\n",
    "    \"\"\"\n",
    "    Fetches a web page with retries and exponential backoff.\n",
    "    Args:\n",
    "        url (str): The URL of the web page to fetch.\n",
    "        verbose (bool): If True, prints status messages.\n",
    "    Returns:\n",
    "        str: The content of the web page, or None if failed.\n",
    "    \"\"\"\n",
    "    wait_time = 1\n",
    "\n",
    "    while True:\n",
    "        if wait_time > 60:\n",
    "            if verbose:\n",
    "                print(f\"Falha ao fazer o fetch de {url} depois de várias tentativas.\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            # Forçando um erro se a resposta não for bem-sucedida\n",
    "            response.raise_for_status()\n",
    "            if verbose:\n",
    "                print(f\"Fetch da {url} feito com sucesso\")\n",
    "            return response.text\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Erro ao fazer o fetch de {url}: {e}. Tentando novamente em {wait_time} segundos...\"\n",
    "                )\n",
    "\n",
    "            time.sleep(wait_time)\n",
    "            # Backoff exponencial\n",
    "            wait_time *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64dbe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_job_details(job_id, is_remote, verbose=False):\n",
    "    \"\"\"\n",
    "    Fetches job details from LinkedIn job posting.\n",
    "    Args:\n",
    "        job_id (str): The ID of the job to fetch.\n",
    "        is_remote (bool): Whether the job is remote.\n",
    "        verbose (bool): If True, prints status messages.\n",
    "    Returns:\n",
    "        dict: A dictionary containing job details, or None if failed.\n",
    "    \"\"\"\n",
    "    job_url = f\"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_id}\"\n",
    "\n",
    "    job_data = fetch_page(job_url, verbose)\n",
    "    # Se a vaga não foi encontrada ou ocorreu um erro, ignorar ela\n",
    "    if not job_data:\n",
    "        return None\n",
    "\n",
    "    # Fazer o parsing do HTML da vaga\n",
    "    soup = BeautifulSoup(job_data, \"html.parser\")\n",
    "\n",
    "    # Informações sobre a vaga\n",
    "    job_name = soup.select_one(\".top-card-layout__entity-info a\")\n",
    "    job_location = soup.select_one(\".topcard__flavor-row .topcard__flavor--bullet\")\n",
    "    job_description = soup.select_one(\".description__text\")\n",
    "    job_remote = is_remote\n",
    "\n",
    "    # Ignorando a vaga se alguma informação estiver faltando\n",
    "    if not job_name or not job_location or not job_description:\n",
    "        if verbose:\n",
    "            print(f\"Pulando vaga {job_id} devido a informações faltantes.\")\n",
    "        return None\n",
    "\n",
    "    # Criando um dicionário para armazenar os detalhes da vaga\n",
    "    job_details = {\n",
    "        \"id\": job_id,\n",
    "        \"name\": job_name.get_text(strip=True),\n",
    "        \"location\": job_location.get_text(strip=True),\n",
    "        \"description\": job_description.get_text(strip=True),\n",
    "        \"remote\": job_remote,\n",
    "    }\n",
    "\n",
    "    return job_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c2e0fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_location = \"Brazil\"\n",
    "maximum_time = \"r86400\"  # considerando apenas vagas das últimas 24 horas\n",
    "\n",
    "\n",
    "def fetch_jobs_with_keywords(keywords, verbose=False):\n",
    "    \"\"\"\n",
    "    Fetches job details from LinkedIn using a certain keyword. Considers both remote and non-remote jobs.\n",
    "    Args:\n",
    "        keywords (str): The keywords to search for.\n",
    "        verbose (bool): If True, prints status messages.\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing job details, or an empty list if nothing was found.\n",
    "    \"\"\"\n",
    "    all_jobs = []\n",
    "\n",
    "    base_search_url = (\n",
    "        \"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search\"\n",
    "    )\n",
    "\n",
    "    keywords = keywords.replace(\" \", \"%20\")\n",
    "\n",
    "    # Buscando vagas remotas e não remotas\n",
    "    for is_remote in [False, True]:\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Buscando vagas {'remotas' if is_remote else 'não remotas'} para a palavra-chave: {keywords}\"\n",
    "            )\n",
    "\n",
    "        # Adicionando palavra-chave, localização, parâmetro de tempo e filtro remoto/não-remoto\n",
    "        location = job_location\n",
    "        time = maximum_time\n",
    "        remote = \"2\" if is_remote else \"1%2C3\"\n",
    "\n",
    "        search_url = f\"{base_search_url}?keywords={keywords}&location={location}&f_TPR={time}&f_WT={remote}&start={{}}\"\n",
    "\n",
    "        pagination_index = 0\n",
    "        while True:\n",
    "            jobs = fetch_page(search_url.format(pagination_index), verbose)\n",
    "\n",
    "            # Se houve um erro ao buscar a página, parar a busca\n",
    "            if not jobs:\n",
    "                break\n",
    "\n",
    "            # Fazendo o parse das vagas\n",
    "            soup = BeautifulSoup(jobs, \"html.parser\")\n",
    "\n",
    "            # Verificando se não há vagas encontradas\n",
    "            total_jobs = soup.find_all(\"li\")\n",
    "            if not total_jobs:\n",
    "                if verbose:\n",
    "                    print(f\"Não há mais vagas na página {pagination_index}.\")\n",
    "                break\n",
    "\n",
    "            # Extraindo detalhes da vaga para cada vaga\n",
    "            for job in total_jobs:\n",
    "                job_id = (\n",
    "                    job.find(\"div\", {\"class\": \"base-card\"})\n",
    "                    .get(\"data-entity-urn\")\n",
    "                    .split(\":\")[3]\n",
    "                    if job.find(\"div\", {\"class\": \"base-card\"})\n",
    "                    else None\n",
    "                )\n",
    "\n",
    "                if job_id is None:\n",
    "                    # Não há mais vagas para processar\n",
    "                    break\n",
    "\n",
    "                job_information = fetch_job_details(job_id, is_remote, verbose)\n",
    "\n",
    "                # Adicionando a vaga se todas as informações foram obtidas\n",
    "                if job_information:\n",
    "                    all_jobs.append(job_information)\n",
    "\n",
    "            # Passando para a próxima página\n",
    "            pagination_index += len(total_jobs)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Total de vagas obtidas: {len(all_jobs)}\")\n",
    "\n",
    "    return all_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3db054",
   "metadata": {},
   "source": [
    "**Palavras-chave para as buscas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1f180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords de busca\n",
    "keywords = [\n",
    "    \"Desenvolvedor\",\n",
    "    \"Programador\",\n",
    "    \"Software\",\n",
    "    \"Hardware\",\n",
    "    \"IA\",\n",
    "    \"Inteligência Artificial\",\n",
    "    \"Machine Learning\",\n",
    "    \"Data Science\",\n",
    "    \"Engenheiro de Software\",\n",
    "    \"Engenheiro de Dados\",\n",
    "    \"Desenvolvimento Web\",\n",
    "    \"Backend\",\n",
    "    \"Frontend\",\n",
    "    \"Full Stack\",\n",
    "    \"Cloud\",\n",
    "    \"DevOps\",\n",
    "    \"Big Data\",\n",
    "    \"QA\",\n",
    "    \"UX\",\n",
    "    \"UI\",\n",
    "    \"CI\",\n",
    "    \"CD\",\n",
    "    \"Android\",\n",
    "    \"iOS\",\n",
    "    \"Mobile\",\n",
    "    \"TI\",\n",
    "    \"Cibersegurança\",\n",
    "    \"Redes\",\n",
    "    \"Robótica\",\n",
    "    \"Jogos\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f0833",
   "metadata": {},
   "source": [
    "**Coleta de dados usando as palavras-chave definidas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f7684a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foram encontradas e salvas 3290 vagas\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "\n",
    "# Buscando vagas para cada palavra-chave e salvando tudo em um arquivo CSV\n",
    "all_jobs_data = []\n",
    "for keyword in keywords:\n",
    "    jobs = fetch_jobs_with_keywords(keyword, verbose)\n",
    "\n",
    "    if jobs:\n",
    "        all_jobs_data.extend(jobs)\n",
    "\n",
    "# Convertendo em um DataFrame, removendo possíveis vagas duplicadas e salvando como CSV\n",
    "if all_jobs_data:\n",
    "    df = pd.DataFrame(all_jobs_data)\n",
    "    # Busca do LinkedIn: vagas podem aparecer em diferentes palavras-chave\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    csv_filename = f\"linkedinjobs_{datetime.today().strftime('%Y-%m-%d')}.csv\"\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    print(f\"Foram encontradas e salvas {len(all_jobs_data)} vagas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
